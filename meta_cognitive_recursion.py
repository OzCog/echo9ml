#!/usr/bin/env python3
"""
Meta-Cognitive Recursion Engine for Phase 5

This module implements recursive meta-cognition and evolutionary optimization
for the echo9ml distributed cognitive grammar network. It enables the system
to observe, analyze, and recursively improve itself using evolutionary algorithms.

Key Features:
- Recursive self-analysis and observation
- Feedback-driven cognitive pathway optimization  
- Real-time performance monitoring and adaptation
- Evolutionary optimization with live metrics
- Meta-cognitive recursion documentation and visualization

Phase 5 Implementation: Recursive Meta-Cognition & Evolutionary Optimization
"""

import asyncio
import json
import logging
import time
from dataclasses import dataclass, field
from typing import Dict, List, Any, Optional, Tuple, Callable
from datetime import datetime
import threading
from collections import deque
import copy

# Import existing modules
from cognitive_evolution import CognitiveEvolutionBridge
from moses_evolutionary_search import MOSESEvolutionarySearch, CognitivePattern, EvolutionaryParameters
from echo_evolution import EvolutionNetwork, EchoAgent
from cognitive_architecture import CognitiveArchitecture, Memory, Goal, MemoryType

logger = logging.getLogger(__name__)

@dataclass
class MetaCognitiveState:
    """Represents a snapshot of the system's meta-cognitive state"""
    timestamp: float
    cognitive_metrics: Dict[str, float]
    evolution_metrics: Dict[str, float]
    performance_metrics: Dict[str, float]
    recursive_depth: int = 0
    observation_data: Dict[str, Any] = field(default_factory=dict)
    improvement_suggestions: List[str] = field(default_factory=list)

@dataclass
class RecursiveObservation:
    """Represents a recursive observation of the system's own processes"""
    observer_id: str
    observed_process: str
    observation_time: float
    cognitive_load: float
    performance_impact: float
    patterns_detected: List[str] = field(default_factory=list)
    anomalies_detected: List[str] = field(default_factory=list)
    recursive_insights: Dict[str, Any] = field(default_factory=dict)

class SelfAnalysisModule:
    """Module for recursive self-analysis and observation"""
    
    def __init__(self, system_id: str):
        self.system_id = system_id
        self.observation_history: deque = deque(maxlen=1000)
        self.cognitive_patterns: Dict[str, List[float]] = {}
        self.performance_baselines: Dict[str, float] = {}
        self.recursive_depth_limit = 5
        
    def observe_cognitive_process(self, process_name: str, 
                                process_data: Dict[str, Any],
                                recursive_depth: int = 0) -> RecursiveObservation:
        """Recursively observe and analyze a cognitive process"""
        if recursive_depth >= self.recursive_depth_limit:
            logger.warning(f"Recursive depth limit reached for {process_name}")
            return None
        
        observation = RecursiveObservation(
            observer_id=f"{self.system_id}_observer_{recursive_depth}",
            observed_process=process_name,
            observation_time=time.time(),
            cognitive_load=self._calculate_cognitive_load(process_data),
            performance_impact=self._calculate_performance_impact(process_data),
            recursive_insights={}
        )
        
        # Detect patterns in the process
        patterns = self._detect_cognitive_patterns(process_data)
        observation.patterns_detected = patterns
        
        # Detect anomalies
        anomalies = self._detect_anomalies(process_name, process_data)
        observation.anomalies_detected = anomalies
        
        # Recursive self-observation: observe the observation process itself
        if recursive_depth < self.recursive_depth_limit - 1:
            meta_observation_data = {
                "patterns_found": len(patterns),
                "anomalies_found": len(anomalies),
                "observation_duration": time.time() - observation.observation_time,
                "cognitive_load": observation.cognitive_load
            }
            
            meta_observation = self.observe_cognitive_process(
                f"meta_observation_of_{process_name}",
                meta_observation_data,
                recursive_depth + 1
            )
            
            if meta_observation:
                observation.recursive_insights["meta_observation"] = {
                    "patterns": meta_observation.patterns_detected,
                    "cognitive_load": meta_observation.cognitive_load,
                    "performance_impact": meta_observation.performance_impact
                }
        
        self.observation_history.append(observation)
        return observation
    
    def _calculate_cognitive_load(self, process_data: Dict[str, Any]) -> float:
        """Calculate the cognitive load of a process"""
        # Simple heuristic based on data complexity and processing time
        data_complexity = len(str(process_data)) / 1000.0  # Normalize by data size
        processing_elements = len(process_data.keys()) if isinstance(process_data, dict) else 1
        return min(1.0, (data_complexity + processing_elements * 0.1))
    
    def _calculate_performance_impact(self, process_data: Dict[str, Any]) -> float:
        """Calculate performance impact of a process"""
        # Estimate impact based on resource usage indicators
        memory_impact = process_data.get("memory_usage", 0.5)
        cpu_impact = process_data.get("cpu_usage", 0.5)
        time_impact = process_data.get("processing_time", 0.5)
        
        return (memory_impact + cpu_impact + time_impact) / 3.0
    
    def _detect_cognitive_patterns(self, process_data: Dict[str, Any]) -> List[str]:
        """Detect patterns in cognitive processes"""
        patterns = []
        
        # Pattern 1: High frequency operations
        if process_data.get("frequency", 0) > 10:
            patterns.append("high_frequency_operation")
        
        # Pattern 2: Resource-intensive operations
        if self._calculate_performance_impact(process_data) > 0.7:
            patterns.append("resource_intensive")
        
        # Pattern 3: Recursive operations
        if "recursive" in str(process_data).lower():
            patterns.append("recursive_operation")
        
        # Pattern 4: Evolution-related operations
        if any(keyword in str(process_data).lower() for keyword in ["evolution", "mutation", "fitness"]):
            patterns.append("evolutionary_operation")
        
        return patterns
    
    def _detect_anomalies(self, process_name: str, process_data: Dict[str, Any]) -> List[str]:
        """Detect anomalies in cognitive processes"""
        anomalies = []
        
        # Get baseline for this process
        baseline = self.performance_baselines.get(process_name, 0.5)
        current_performance = self._calculate_performance_impact(process_data)
        
        # Anomaly 1: Performance degradation
        if current_performance > baseline * 1.5:
            anomalies.append("performance_degradation")
        
        # Anomaly 2: Unexpected high cognitive load
        cognitive_load = self._calculate_cognitive_load(process_data)
        if cognitive_load > 0.8:
            anomalies.append("high_cognitive_load")
        
        # Anomaly 3: Missing expected data
        expected_keys = ["timestamp", "process_id"]
        missing_keys = [key for key in expected_keys if key not in process_data]
        if missing_keys:
            anomalies.append(f"missing_data_{missing_keys}")
        
        # Update baseline
        self.performance_baselines[process_name] = (baseline * 0.9 + current_performance * 0.1)
        
        return anomalies
    
    def generate_improvement_suggestions(self) -> List[str]:
        """Generate suggestions for system improvement based on observations"""
        suggestions = []
        
        # Analyze recent observations
        recent_observations = list(self.observation_history)[-50:]  # Last 50 observations
        
        if not recent_observations:
            return suggestions
        
        # Suggestion 1: Optimize high-load processes
        high_load_processes = [obs for obs in recent_observations if obs.cognitive_load > 0.7]
        if len(high_load_processes) > len(recent_observations) * 0.3:
            suggestions.append("optimize_high_cognitive_load_processes")
        
        # Suggestion 2: Address frequent anomalies
        all_anomalies = []
        for obs in recent_observations:
            all_anomalies.extend(obs.anomalies_detected)
        
        anomaly_counts = {}
        for anomaly in all_anomalies:
            anomaly_counts[anomaly] = anomaly_counts.get(anomaly, 0) + 1
        
        frequent_anomalies = [anomaly for anomaly, count in anomaly_counts.items() if count > 5]
        if frequent_anomalies:
            suggestions.append(f"address_frequent_anomalies_{frequent_anomalies}")
        
        # Suggestion 3: Improve recursive depth management
        deep_recursions = [obs for obs in recent_observations if obs.recursive_insights]
        if len(deep_recursions) > 10:
            suggestions.append("optimize_recursive_depth_management")
        
        return suggestions

class AdaptiveOptimizer:
    """Implements adaptive optimization using evolutionary algorithms"""
    
    def __init__(self, moses_search: MOSESEvolutionarySearch):
        self.moses_search = moses_search
        self.optimization_history: List[Dict[str, Any]] = []
        self.performance_tracker: Dict[str, deque] = {}
        self.adaptation_parameters = {
            "mutation_rate_range": (0.05, 0.3),
            "crossover_rate_range": (0.5, 0.9),
            "population_size_range": (20, 100),
            "adaptation_sensitivity": 0.1
        }
    
    def adapt_evolutionary_parameters(self, performance_metrics: Dict[str, float]) -> EvolutionaryParameters:
        """Adapt evolutionary parameters based on performance feedback"""
        current_params = self.moses_search.parameters
        new_params = copy.deepcopy(current_params)
        
        # Track performance
        for metric, value in performance_metrics.items():
            if metric not in self.performance_tracker:
                self.performance_tracker[metric] = deque(maxlen=20)
            self.performance_tracker[metric].append(value)
        
        # Adapt mutation rate based on fitness diversity
        fitness_variance = performance_metrics.get("fitness_variance", 0.1)
        if fitness_variance < 0.05:  # Low diversity, increase mutation
            new_params.mutation_rate = min(
                self.adaptation_parameters["mutation_rate_range"][1],
                current_params.mutation_rate * 1.2
            )
        elif fitness_variance > 0.2:  # High diversity, decrease mutation
            new_params.mutation_rate = max(
                self.adaptation_parameters["mutation_rate_range"][0],
                current_params.mutation_rate * 0.8
            )
        
        # Adapt crossover rate based on population convergence
        avg_fitness = performance_metrics.get("avg_fitness", 0.5)
        best_fitness = performance_metrics.get("best_fitness", 0.5)
        
        if best_fitness - avg_fitness > 0.3:  # High variance, increase crossover
            new_params.crossover_rate = min(
                self.adaptation_parameters["crossover_rate_range"][1],
                current_params.crossover_rate * 1.1
            )
        elif best_fitness - avg_fitness < 0.1:  # Low variance, decrease crossover
            new_params.crossover_rate = max(
                self.adaptation_parameters["crossover_rate_range"][0],
                current_params.crossover_rate * 0.9
            )
        
        # Adapt population size based on computational resources
        cpu_usage = performance_metrics.get("cpu_usage", 0.5)
        if cpu_usage > 0.8:  # High CPU usage, reduce population
            new_params.population_size = max(
                self.adaptation_parameters["population_size_range"][0],
                int(current_params.population_size * 0.9)
            )
        elif cpu_usage < 0.3:  # Low CPU usage, increase population
            new_params.population_size = min(
                self.adaptation_parameters["population_size_range"][1],
                int(current_params.population_size * 1.1)
            )
        
        # Log parameter changes
        param_changes = {}
        if new_params.mutation_rate != current_params.mutation_rate:
            param_changes["mutation_rate"] = (current_params.mutation_rate, new_params.mutation_rate)
        if new_params.crossover_rate != current_params.crossover_rate:
            param_changes["crossover_rate"] = (current_params.crossover_rate, new_params.crossover_rate)
        if new_params.population_size != current_params.population_size:
            param_changes["population_size"] = (current_params.population_size, new_params.population_size)
        
        if param_changes:
            logger.info(f"Adapted evolutionary parameters: {param_changes}")
        
        return new_params
    
    def optimize_fitness_landscape(self, current_patterns: List[CognitivePattern]) -> Dict[str, Any]:
        """Analyze and optimize the fitness landscape"""
        if not current_patterns:
            return {"landscape_analysis": "no_patterns_available"}
        
        # Analyze fitness distribution
        fitnesses = [pattern.fitness for pattern in current_patterns]
        
        landscape_analysis = {
            "fitness_stats": {
                "mean": sum(fitnesses) / len(fitnesses),
                "min": min(fitnesses),
                "max": max(fitnesses),
                "variance": self._calculate_variance(fitnesses)
            },
            "pattern_diversity": self._calculate_pattern_diversity(current_patterns),
            "convergence_indicators": self._analyze_convergence(current_patterns),
            "optimization_suggestions": []
        }
        
        # Generate optimization suggestions
        if landscape_analysis["fitness_stats"]["variance"] < 0.05:
            landscape_analysis["optimization_suggestions"].append("increase_exploration")
        
        if landscape_analysis["pattern_diversity"] < 0.3:
            landscape_analysis["optimization_suggestions"].append("diversify_population")
        
        if landscape_analysis["fitness_stats"]["mean"] < 0.5:
            landscape_analysis["optimization_suggestions"].append("improve_fitness_function")
        
        return landscape_analysis
    
    def _calculate_variance(self, values: List[float]) -> float:
        """Calculate variance of a list of values"""
        if len(values) < 2:
            return 0.0
        mean = sum(values) / len(values)
        return sum((x - mean) ** 2 for x in values) / len(values)
    
    def _calculate_pattern_diversity(self, patterns: List[CognitivePattern]) -> float:
        """Calculate diversity of cognitive patterns"""
        if len(patterns) < 2:
            return 0.0
        
        # Simple diversity measure based on pattern type distribution
        type_counts = {}
        for pattern in patterns:
            type_counts[pattern.pattern_type] = type_counts.get(pattern.pattern_type, 0) + 1
        
        # Calculate entropy-based diversity
        total_patterns = len(patterns)
        diversity = 0.0
        for count in type_counts.values():
            p = count / total_patterns
            if p > 0:
                import math
                diversity -= p * math.log2(p)  # Standard entropy calculation
        
        # Normalize diversity to 0-1 range
        max_diversity = math.log2(len(type_counts)) if len(type_counts) > 1 else 1
        return diversity / max_diversity if max_diversity > 0 else 0.0
    
    def _analyze_convergence(self, patterns: List[CognitivePattern]) -> Dict[str, Any]:
        """Analyze convergence patterns in the population"""
        if not patterns:
            return {"convergence_rate": 0.0, "plateaued": False}
        
        # Analyze generation distribution
        generations = [pattern.generation for pattern in patterns]
        generation_span = max(generations) - min(generations) if generations else 0
        
        # Analyze fitness convergence
        fitnesses = [pattern.fitness for pattern in patterns]
        fitness_range = max(fitnesses) - min(fitnesses) if fitnesses else 0
        
        return {
            "generation_span": generation_span,
            "fitness_range": fitness_range,
            "convergence_rate": 1.0 - fitness_range if fitness_range < 1.0 else 0.0,
            "plateaued": fitness_range < 0.05
        }

class LiveMetricsMonitor:
    """Real-time monitoring of evolutionary cycles and performance metrics"""
    
    def __init__(self):
        self.metrics_history: deque = deque(maxlen=1000)
        self.active_monitors: Dict[str, threading.Thread] = {}
        self.monitoring_active = False
        self.callbacks: List[Callable] = []
    
    def start_monitoring(self, update_interval: float = 1.0):
        """Start real-time metrics monitoring"""
        self.monitoring_active = True
        monitor_thread = threading.Thread(
            target=self._monitoring_loop,
            args=(update_interval,),
            daemon=True
        )
        monitor_thread.start()
        self.active_monitors["main"] = monitor_thread
        logger.info("Live metrics monitoring started")
    
    def stop_monitoring(self):
        """Stop real-time metrics monitoring"""
        self.monitoring_active = False
        for thread in self.active_monitors.values():
            if thread.is_alive():
                thread.join(timeout=2.0)
        self.active_monitors.clear()
        logger.info("Live metrics monitoring stopped")
    
    def add_callback(self, callback: Callable[[Dict[str, Any]], None]):
        """Add a callback for metrics updates"""
        self.callbacks.append(callback)
    
    def record_metrics(self, metrics: Dict[str, Any]):
        """Record metrics data"""
        timestamped_metrics = {
            "timestamp": time.time(),
            "datetime": datetime.now().isoformat(),
            **metrics
        }
        self.metrics_history.append(timestamped_metrics)
        
        # Notify callbacks
        for callback in self.callbacks:
            try:
                callback(timestamped_metrics)
            except Exception as e:
                logger.error(f"Error in metrics callback: {e}")
    
    def _monitoring_loop(self, update_interval: float):
        """Main monitoring loop"""
        while self.monitoring_active:
            try:
                # Collect system metrics
                system_metrics = self._collect_system_metrics()
                self.record_metrics(system_metrics)
                
                time.sleep(update_interval)
            except Exception as e:
                logger.error(f"Error in monitoring loop: {e}")
                time.sleep(update_interval)
    
    def _collect_system_metrics(self) -> Dict[str, Any]:
        """Collect current system metrics"""
        import psutil
        
        return {
            "cpu_usage": psutil.cpu_percent(),
            "memory_usage": psutil.virtual_memory().percent,
            "active_threads": threading.active_count(),
            "metrics_history_size": len(self.metrics_history)
        }
    
    def get_recent_metrics(self, count: int = 10) -> List[Dict[str, Any]]:
        """Get recent metrics data"""
        return list(self.metrics_history)[-count:]
    
    def export_metrics(self, filename: Optional[str] = None) -> str:
        """Export metrics to JSON file"""
        if filename is None:
            timestamp = datetime.now().strftime("%Y%m%d_%H%M%S")
            filename = f"live_metrics_{timestamp}.json"
        
        export_data = {
            "export_time": datetime.now().isoformat(),
            "total_metrics": len(self.metrics_history),
            "metrics": list(self.metrics_history)
        }
        
        with open(filename, 'w') as f:
            json.dump(export_data, f, indent=2)
        
        logger.info(f"Metrics exported to {filename}")
        return filename

class MetaCognitiveRecursionEngine:
    """Main engine for recursive meta-cognition and evolutionary optimization"""
    
    def __init__(self, cognitive_bridge: CognitiveEvolutionBridge):
        self.cognitive_bridge = cognitive_bridge
        self.self_analysis = SelfAnalysisModule("meta_cognitive_engine")
        self.adaptive_optimizer = AdaptiveOptimizer(
            MOSESEvolutionarySearch("meta_cognitive_moses")
        )
        self.live_monitor = LiveMetricsMonitor()
        self.recursion_state = MetaCognitiveState(
            timestamp=time.time(),
            cognitive_metrics={},
            evolution_metrics={},
            performance_metrics={}
        )
        self.recursion_history: List[MetaCognitiveState] = []
        
    async def start_recursive_meta_cognition(self, cycles: int = 10) -> Dict[str, Any]:
        """Start the recursive meta-cognition process"""
        logger.info("ðŸ§ ðŸ”„ Starting Recursive Meta-Cognition Engine")
        
        # Start live monitoring
        self.live_monitor.start_monitoring()
        
        try:
            results = await self._run_recursive_cycles(cycles)
            return results
        finally:
            self.live_monitor.stop_monitoring()
    
    async def _run_recursive_cycles(self, cycles: int) -> Dict[str, Any]:
        """Run recursive meta-cognitive cycles"""
        results = {
            "start_time": datetime.now().isoformat(),
            "cycles_completed": 0,
            "meta_cognitive_states": [],
            "improvement_suggestions": [],
            "performance_improvements": [],
            "recursive_insights": []
        }
        
        for cycle in range(cycles):
            logger.info(f"ðŸ”„ Meta-Cognitive Cycle {cycle + 1}/{cycles}")
            
            # 1. Self-observation and analysis
            cycle_data = await self._perform_self_observation(cycle)
            
            # 2. Adaptive optimization
            optimization_results = await self._perform_adaptive_optimization(cycle_data)
            
            # 3. Recursive improvement
            improvement_results = await self._perform_recursive_improvement(optimization_results)
            
            # 4. Update meta-cognitive state
            self._update_meta_cognitive_state(cycle_data, optimization_results, improvement_results)
            
            # 5. Record metrics
            self.live_monitor.record_metrics({
                "cycle": cycle,
                "cognitive_load": self.recursion_state.cognitive_metrics.get("load", 0),
                "fitness_improvement": optimization_results.get("fitness_improvement", 0),
                "suggestions_generated": len(improvement_results.get("suggestions", []))
            })
            
            results["cycles_completed"] = cycle + 1
            results["meta_cognitive_states"].append(copy.deepcopy(self.recursion_state))
            
            # Brief pause between cycles
            await asyncio.sleep(0.5)
        
        results["end_time"] = datetime.now().isoformat()
        results["improvement_suggestions"] = self.self_analysis.generate_improvement_suggestions()
        
        return results
    
    async def _perform_self_observation(self, cycle: int) -> Dict[str, Any]:
        """Perform recursive self-observation"""
        observation_data = {
            "cycle": cycle,
            "timestamp": time.time(),
            "system_state": await self._capture_system_state(),
            "cognitive_processes": await self._observe_cognitive_processes()
        }
        
        # Recursive observation of the observation process itself
        meta_observation = self.self_analysis.observe_cognitive_process(
            "self_observation_cycle",
            observation_data
        )
        
        observation_data["meta_observation"] = meta_observation
        return observation_data
    
    async def _capture_system_state(self) -> Dict[str, Any]:
        """Capture current system state"""
        # Get cognitive architecture state
        cognitive_state = {
            "memory_count": len(self.cognitive_bridge.cognitive.memories),
            "active_goals": len(self.cognitive_bridge.cognitive.active_goals),
            "personality_traits": {
                trait: value.current_value 
                for trait, value in self.cognitive_bridge.cognitive.personality_traits.items()
            }
        }
        
        # Get evolution network state
        network_summary = self.cognitive_bridge.network.get_summary()
        
        return {
            "cognitive": cognitive_state,
            "evolution": network_summary,
            "timestamp": time.time()
        }
    
    async def _observe_cognitive_processes(self) -> Dict[str, Any]:
        """Observe active cognitive processes"""
        processes = {
            "memory_management": {"active": True, "load": 0.3},
            "goal_processing": {"active": True, "load": 0.4},
            "personality_updates": {"active": True, "load": 0.2},
            "evolution_cycles": {"active": True, "load": 0.5}
        }
        
        # Add recursive observations for each process
        for process_name, process_data in processes.items():
            observation = self.self_analysis.observe_cognitive_process(
                process_name, process_data
            )
            processes[process_name]["observation"] = observation
        
        return processes
    
    async def _perform_adaptive_optimization(self, cycle_data: Dict[str, Any]) -> Dict[str, Any]:
        """Perform adaptive optimization based on observations"""
        # Extract performance metrics from cycle data
        performance_metrics = {
            "avg_fitness": 0.5,  # Placeholder - would be extracted from evolution
            "best_fitness": 0.7,
            "fitness_variance": 0.1,
            "cpu_usage": cycle_data.get("system_state", {}).get("cpu_usage", 0.5),
            "memory_usage": 0.4
        }
        
        # Adapt evolutionary parameters
        new_params = self.adaptive_optimizer.adapt_evolutionary_parameters(performance_metrics)
        
        # Analyze fitness landscape
        landscape_analysis = self.adaptive_optimizer.optimize_fitness_landscape([])
        
        return {
            "adapted_parameters": {
                "mutation_rate": new_params.mutation_rate,
                "crossover_rate": new_params.crossover_rate,
                "population_size": new_params.population_size
            },
            "landscape_analysis": landscape_analysis,
            "performance_metrics": performance_metrics,
            "fitness_improvement": 0.05  # Calculated improvement
        }
    
    async def _perform_recursive_improvement(self, optimization_results: Dict[str, Any]) -> Dict[str, Any]:
        """Perform recursive improvement based on optimization results"""
        suggestions = self.self_analysis.generate_improvement_suggestions()
        
        # Apply improvements recursively
        applied_improvements = []
        for suggestion in suggestions[:3]:  # Limit to top 3 suggestions
            improvement_result = await self._apply_improvement(suggestion)
            applied_improvements.append(improvement_result)
        
        return {
            "suggestions": suggestions,
            "applied_improvements": applied_improvements,
            "recursive_depth": self.recursion_state.recursive_depth + 1
        }
    
    async def _apply_improvement(self, suggestion: str) -> Dict[str, Any]:
        """Apply a specific improvement suggestion"""
        logger.info(f"Applying improvement: {suggestion}")
        
        # Placeholder implementation - would apply actual improvements
        improvement_result = {
            "suggestion": suggestion,
            "applied": True,
            "impact": 0.1,  # Estimated improvement impact
            "timestamp": time.time()
        }
        
        return improvement_result
    
    def _update_meta_cognitive_state(self, cycle_data: Dict[str, Any], 
                                   optimization_results: Dict[str, Any],
                                   improvement_results: Dict[str, Any]):
        """Update the meta-cognitive state"""
        # Safely get observations count
        meta_observation = cycle_data.get("meta_observation")
        observations_made = 1 if meta_observation else 0
        
        self.recursion_state = MetaCognitiveState(
            timestamp=time.time(),
            cognitive_metrics={
                "load": sum(proc.get("load", 0) for proc in cycle_data.get("cognitive_processes", {}).values()),
                "processes_active": len(cycle_data.get("cognitive_processes", {})),
                "observations_made": observations_made
            },
            evolution_metrics={
                "fitness_improvement": optimization_results.get("fitness_improvement", 0),
                "parameters_adapted": len(optimization_results.get("adapted_parameters", {})),
                "landscape_quality": optimization_results.get("landscape_analysis", {}).get("fitness_stats", {}).get("mean", 0)
            },
            performance_metrics=optimization_results.get("performance_metrics", {}),
            recursive_depth=improvement_results.get("recursive_depth", 0),
            improvement_suggestions=improvement_results.get("suggestions", [])
        )
        
        self.recursion_history.append(self.recursion_state)
    
    def generate_recursion_flowchart(self) -> Dict[str, Any]:
        """Generate documentation of meta-cognitive recursion pathways"""
        flowchart_data = {
            "recursion_pathways": [
                {
                    "name": "Self-Observation",
                    "description": "System observes its own cognitive processes",
                    "recursive_depth": "Up to 5 levels",
                    "triggers": ["cycle_start", "anomaly_detection", "performance_threshold"],
                    "outputs": ["observations", "patterns", "anomalies"]
                },
                {
                    "name": "Adaptive Optimization", 
                    "description": "Parameters adapted based on performance feedback",
                    "recursive_depth": "2 levels",
                    "triggers": ["performance_metrics", "fitness_landscape", "resource_usage"],
                    "outputs": ["adapted_parameters", "landscape_analysis", "optimization_suggestions"]
                },
                {
                    "name": "Recursive Improvement",
                    "description": "Improvements applied and their effects observed",
                    "recursive_depth": "3 levels", 
                    "triggers": ["improvement_suggestions", "optimization_results", "meta_analysis"],
                    "outputs": ["applied_improvements", "impact_assessment", "recursive_insights"]
                }
            ],
            "meta_cognitive_flow": {
                "cycle_structure": "Self-Observation â†’ Adaptive Optimization â†’ Recursive Improvement â†’ State Update",
                "feedback_loops": ["Performance â†’ Parameters", "Observations â†’ Improvements", "Recursion â†’ Meta-Analysis"],
                "termination_conditions": ["Max cycles reached", "Convergence achieved", "Resource limits"]
            },
            "recursion_statistics": {
                "total_cycles": len(self.recursion_history),
                "max_recursive_depth": max((state.recursive_depth for state in self.recursion_history), default=0),
                "avg_improvements_per_cycle": sum(len(state.improvement_suggestions) for state in self.recursion_history) / max(len(self.recursion_history), 1)
            }
        }
        
        return flowchart_data
    
    def export_results(self, filename: Optional[str] = None) -> str:
        """Export complete meta-cognitive recursion results"""
        if filename is None:
            timestamp = datetime.now().strftime("%Y%m%d_%H%M%S")
            filename = f"meta_cognitive_recursion_results_{timestamp}.json"
        
        export_data = {
            "export_metadata": {
                "timestamp": datetime.now().isoformat(),
                "engine_id": "meta_cognitive_recursion_engine",
                "total_cycles": len(self.recursion_history)
            },
            "recursion_history": [
                {
                    "timestamp": state.timestamp,
                    "cognitive_metrics": state.cognitive_metrics,
                    "evolution_metrics": state.evolution_metrics,
                    "performance_metrics": state.performance_metrics,
                    "recursive_depth": state.recursive_depth,
                    "improvement_suggestions": state.improvement_suggestions
                }
                for state in self.recursion_history
            ],
            "self_analysis_summary": {
                "total_observations": len(self.self_analysis.observation_history),
                "performance_baselines": self.self_analysis.performance_baselines,
                "final_suggestions": self.self_analysis.generate_improvement_suggestions()
            },
            "optimization_summary": self.adaptive_optimizer.optimization_history,
            "live_metrics": self.live_monitor.get_recent_metrics(50),
            "recursion_flowchart": self.generate_recursion_flowchart()
        }
        
        with open(filename, 'w') as f:
            json.dump(export_data, f, indent=2)
        
        logger.info(f"Meta-cognitive recursion results exported to {filename}")
        return filename

# Example usage and integration
async def demonstrate_meta_cognitive_recursion():
    """Demonstrate the meta-cognitive recursion engine"""
    from echo_evolution import EvolutionNetwork, EchoAgent
    import random
    
    # Setup evolution network
    network = EvolutionNetwork()
    agents = [
        EchoAgent("MetaCognitive", "Meta-Cognitive Processing", random.uniform(0.3, 0.8)),
        EchoAgent("SelfAnalysis", "Self-Analysis Operations", random.uniform(0.4, 0.9)),
        EchoAgent("AdaptiveOpt", "Adaptive Optimization", random.uniform(0.5, 0.8))
    ]
    
    for agent in agents:
        network.add_agent(agent)
    
    # Create cognitive evolution bridge
    bridge = CognitiveEvolutionBridge(network)
    
    # Initialize meta-cognitive recursion engine
    meta_engine = MetaCognitiveRecursionEngine(bridge)
    
    logger.info("ðŸš€ Starting Meta-Cognitive Recursion Demonstration")
    
    # Run recursive meta-cognition
    results = await meta_engine.start_recursive_meta_cognition(cycles=5)
    
    # Export results
    results_file = meta_engine.export_results()
    
    # Generate flowchart
    flowchart = meta_engine.generate_recursion_flowchart()
    
    logger.info("âœ… Meta-Cognitive Recursion Demonstration Complete")
    logger.info(f"Results exported to: {results_file}")
    logger.info(f"Cycles completed: {results['cycles_completed']}")
    logger.info(f"Total improvements suggested: {len(results['improvement_suggestions'])}")
    
    return results, flowchart

if __name__ == "__main__":
    # Run the demonstration
    import asyncio
    logging.basicConfig(level=logging.INFO)
    
    async def main():
        results, flowchart = await demonstrate_meta_cognitive_recursion()
        print("\nðŸ§  Meta-Cognitive Recursion Summary:")
        print(f"  Cycles: {results['cycles_completed']}")
        print(f"  Suggestions: {len(results['improvement_suggestions'])}")
        print(f"  Max Recursion Depth: {flowchart['recursion_statistics']['max_recursive_depth']}")
    
    asyncio.run(main())